{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cs341-data-preprocessing.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "metadata": {
        "id": "er57dhkFMw3r",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "import gzip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EckIxCXG1aa6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Clicks dataset unzip**"
      ]
    },
    {
      "metadata": {
        "id": "wFSOwLmE1Zo7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ALLLLLL INNNNNN ONEEEEE\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "#gzip file unzipping...\n",
        "file_name = {}\n",
        "file_path = {}\n",
        "csv_file_name = {}\n",
        "csv_file_path = {}\n",
        "\n",
        "#upload .csv file back to cloud\n",
        "project_id = 'formal-precinct-236705'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "\n",
        "# Make a unique bucket to which we'll upload the file.\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = 'digital-trend-data-unzipped'\n",
        "\n",
        "medium_path = 'dfp-network-clicks'\n",
        "#upload .csv file back to cloud\n",
        "project_id = 'cs341-lucky'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
        "!gsutil mb gs://{bucket_name}\n",
        "\n",
        "\n",
        "for i in range(32):\n",
        "  if i < 10:\n",
        "    file_name = '000' + str(i) + '_part_00.gz'\n",
        "    trans_file_name = '000' + str(i) + '_part_00.txt'\n",
        "    csv_file_name = '000' + str(i) + '_part_00.csv'\n",
        "    csv_file_path = '/' + csv_file_name\n",
        "  else: \n",
        "    file_name = '00' + str(i) + '_part_00.gz'\n",
        "    trans_file_name = '00' + str(i) + '_part_00.txt'\n",
        "    csv_file_name = '00' + str(i) + '_part_00.csv'\n",
        "    csv_file_path = '/' + csv_file_name\n",
        "\n",
        "  # Download the file.\n",
        "  !gsutil cp gs://digital-trend-raw-data/{medium_path}/{file_name} /{file_name}\n",
        "  \n",
        "  file_path = '/' + file_name\n",
        "  trans_file_path = '/' + trans_file_name\n",
        "  \n",
        "  with gzip.open(file_path, 'rb') as f, open(trans_file_path, 'wb') as f_out:\n",
        "      f_out.write(f.read())\n",
        "    \n",
        "  df = pd.read_csv(trans_file_path, delimiter=',', header=None)\n",
        "  \n",
        "  df.to_csv(csv_file_path, index=False)\n",
        "  \n",
        "  # Copy the file to our new bucket.\n",
        "  # Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "  !gsutil cp {csv_file_path} gs://{bucket_name}/{medium_path}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ULK5flO1Hoka",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "Dh3R_0FTIbal"
      },
      "cell_type": "markdown",
      "source": [
        "## **Wordpress dataset unzip**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "hrVafhQH8ZTZ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#ALLLLLL INNNNNN ONEEEEE\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "#gzip file unzipping...\n",
        "file_name = {}\n",
        "file_path = {}\n",
        "csv_file_name = {}\n",
        "csv_file_path = {}\n",
        "\n",
        "# Make a unique bucket to which we'll upload the file.\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = 'digital-trend-data-unzipped'\n",
        "\n",
        "medium_path = 'wordpress'\n",
        "\n",
        "#upload .csv file back to cloud\n",
        "project_id = 'cs341-lucky'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
        "!gsutil mb gs://{bucket_name}\n",
        "  \n",
        "  \n",
        "for i in range(32):\n",
        "  if i < 10:\n",
        "    file_name = '000' + str(i) + '_part_00.gz'\n",
        "    trans_file_name = '000' + str(i) + '_part_00.txt'\n",
        "    csv_file_name = '000' + str(i) + '_part_00.csv'\n",
        "    csv_file_path = '/' + csv_file_name\n",
        "  else: \n",
        "    file_name = '00' + str(i) + '_part_00.gz'\n",
        "    trans_file_name = '00' + str(i) + '_part_00.txt'\n",
        "    csv_file_name = '00' + str(i) + '_part_00.csv'\n",
        "    csv_file_path = '/' + csv_file_name\n",
        "\n",
        "  # Download the file.\n",
        "  !gsutil cp gs://digital-trend-raw-data/{medium_path}/{file_name} /{file_name}\n",
        "  \n",
        "  file_path = '/' + file_name\n",
        "  trans_file_path = '/' + trans_file_name\n",
        "  \n",
        "  with gzip.open(file_path, 'rb') as f, open(trans_file_path, 'wb') as f_out:\n",
        "      f_out.write(f.read())\n",
        "    \n",
        "  df = pd.read_csv(trans_file_path, delimiter=',', header=None)\n",
        "  \n",
        "  df.to_csv(csv_file_path, index=False)\n",
        "  \n",
        "  # Copy the file to our new bucket.\n",
        "  # Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "  !gsutil cp {csv_file_path} gs://{bucket_name}/{medium_path}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "3sQPVn4rWyng"
      },
      "cell_type": "markdown",
      "source": [
        "## **Snowplow dataset unzip**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "l0A1FLxW99Gf",
        "outputId": "51f2cec3-28ea-418f-a125-593c67465270",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#ALLLLLL INNNNNN ONEEEEE\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "#gzip file unzipping...\n",
        "file_name = {}\n",
        "file_path = {}\n",
        "csv_file_name = {}\n",
        "csv_file_path = {}\n",
        "\n",
        "#upload .csv file back to cloud\n",
        "project_id = 'cs341-lucky'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "# Make a unique bucket to which we'll upload the file.\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = 'digital-trend-data-unzipped'\n",
        "\n",
        "medium_path = 'snowplow/2018-01'\n",
        "\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
        "!gsutil mb gs://{bucket_name}\n",
        "\n",
        "for i in range(1):\n",
        "  for j in range(1):\n",
        "    file_name = '000' + str(i) + '_part_0' + str(j) +'.gz'\n",
        "    trans_file_name = '000' + str(i) + '_part_0' + str(j) +'.txt'\n",
        "    csv_file_name = '000' + str(i) + '_part_0' + str(j) +'.csv'\n",
        "    csv_file_path = '/' + csv_file_name\n",
        "    \n",
        "    # Download the file.\n",
        "    !gsutil cp gs://digital-trend-raw-data/{medium_path}/{file_name} /{file_name}\n",
        "  \n",
        "    file_path = '/' + file_name\n",
        "    trans_file_path = '/' + trans_file_name\n",
        "  \n",
        "    with gzip.open(file_path, 'rb') as f, open(trans_file_path, 'wb') as f_out:\n",
        "        f_out.write(f.read())\n",
        "    \n",
        "    df = pd.read_csv(trans_file_path, delimiter=',', header=None)\n",
        "    df.to_csv(csv_file_path, index=False)\n",
        "    \n",
        "    # Copy the file to our new bucket.\n",
        "    # Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "    !gsutil cp {csv_file_path} gs://{bucket_name}/{medium_path}/"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Creating gs://digital-trend-data-unzipped/...\n",
            "ServiceException: 409 Bucket digital-trend-data-unzipped already exists.\n",
            "Copying gs://digital-trend-raw-data/snowplow/2018-01/0000_part_00.gz...\n",
            "-\n",
            "Operation completed over 1 objects/5.0 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "outputId": "c9f29855-53fc-44bd-f7f1-5ad1cf801f92",
        "id": "NkT9Aor-A3hS",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "cell_type": "code",
      "source": [
        "#ALLLLLL INNNNNN ONEEEEE\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "import pandas as pd\n",
        "import gzip\n",
        "import pandas as pd\n",
        "import gzip\n",
        "\n",
        "#gzip file unzipping...\n",
        "file_name = {}\n",
        "file_path = {}\n",
        "csv_file_name = {}\n",
        "csv_file_path = {}\n",
        "\n",
        "#upload .csv file back to cloud\n",
        "project_id = 'cs341-lucky'\n",
        "!gcloud config set project {project_id}\n",
        "\n",
        "# Make a unique bucket to which we'll upload the file.\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = 'digital-trend-data-unzipped'\n",
        "\n",
        "medium_path = 'snowplow/2018-01'\n",
        "\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
        "!gsutil mb gs://{bucket_name}\n",
        "\n",
        "for i in range(1):\n",
        "  for j in range(1):\n",
        "    file_name = '000' + str(i) + '_part_0' + str(j) +'.gz'\n",
        "    trans_file_name = '000' + str(i) + '_part_0' + str(j) +'.txt'\n",
        "    csv_file_name = '000' + str(i) + '_part_0' + str(j) +'.csv'\n",
        "    csv_file_path = '/' + csv_file_name\n",
        "    \n",
        "    # Download the file.\n",
        "    !gsutil cp gs://digital-trend-raw-data/{medium_path}/{file_name} /{file_name}\n",
        "  \n",
        "    file_path = '/' + file_name\n",
        "    trans_file_path = '/' + trans_file_name\n",
        "  \n",
        "    with gzip.open(file_path, 'rb') as f, open(trans_file_path, 'wb') as f_out:\n",
        "        f_out.write(f.read())\n",
        "    \n",
        "    df = pd.read_csv(trans_file_path, delimiter=',', header=None)\n",
        "    #df.to_csv(csv_file_path, index=False)\n",
        "    \n",
        "    # Copy the file to our new bucket.\n",
        "    # Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "    #!gsutil cp {csv_file_path} gs://{bucket_name}/{medium_path}/\n",
        "    df.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Updated property [core/project].\n",
            "Creating gs://digital-trend-data-unzipped/...\n",
            "ServiceException: 409 Bucket digital-trend-data-unzipped already exists.\n",
            "Copying gs://digital-trend-raw-data/snowplow/2018-01/0000_part_00.gz...\n",
            "|\n",
            "Operation completed over 1 objects/5.0 GiB.                                      \n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}